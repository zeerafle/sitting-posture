{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a9f3a76236dbd8",
   "metadata": {},
   "source": [
    "# Sitting Posture Classification"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:45.481473Z",
     "start_time": "2024-07-27T02:42:39.029615Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from dvclive import Live\n",
    "from dvclive.keras import DVCLiveCallback\n",
    "\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "import seaborn as sns\n",
    "\n",
    "from data import BodyPart"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "caf9d742c85de023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:45.513473Z",
     "start_time": "2024-07-27T02:42:45.483473Z"
    }
   },
   "source": [
    "df = pl.read_csv('data/data.csv')\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (5, 42)\n",
       "┌─────────────┬────────┬────────┬────────────┬───┬────────────┬────────────┬──────────┬────────────┐\n",
       "│ file_name   ┆ NOSE_x ┆ NOSE_y ┆ NOSE_score ┆ … ┆ RIGHT_HIP_ ┆ RIGHT_HIP_ ┆ class_no ┆ class_name │\n",
       "│ ---         ┆ ---    ┆ ---    ┆ ---        ┆   ┆ y          ┆ score      ┆ ---      ┆ ---        │\n",
       "│ str         ┆ f64    ┆ f64    ┆ f64        ┆   ┆ ---        ┆ ---        ┆ i64      ┆ str        │\n",
       "│             ┆        ┆        ┆            ┆   ┆ f64        ┆ f64        ┆          ┆            │\n",
       "╞═════════════╪════════╪════════╪════════════╪═══╪════════════╪════════════╪══════════╪════════════╡\n",
       "│ ergonomis\\D ┆ 2673.0 ┆ 1426.0 ┆ 0.6860288  ┆ … ┆ 2901.0     ┆ 0.5723911  ┆ 0        ┆ ergonomis  │\n",
       "│ SC02412.JPG ┆        ┆        ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ ergonomis\\D ┆ 2553.0 ┆ 1548.0 ┆ 0.6246008  ┆ … ┆ 3009.0     ┆ 0.5088232  ┆ 0        ┆ ergonomis  │\n",
       "│ SC02414.JPG ┆        ┆        ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ ergonomis\\D ┆ 2811.0 ┆ 1522.0 ┆ 0.4514594  ┆ … ┆ 3108.0     ┆ 0.5448222  ┆ 0        ┆ ergonomis  │\n",
       "│ SC02416.JPG ┆        ┆        ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ ergonomis\\D ┆ 2654.0 ┆ 1438.0 ┆ 0.5282986  ┆ … ┆ 2988.0     ┆ 0.5330165  ┆ 0        ┆ ergonomis  │\n",
       "│ SC02418.JPG ┆        ┆        ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "│ ergonomis\\D ┆ 2557.0 ┆ 1550.0 ┆ 0.6233348  ┆ … ┆ 2919.0     ┆ 0.606949   ┆ 0        ┆ ergonomis  │\n",
       "│ SC02416.JPG ┆        ┆        ┆            ┆   ┆            ┆            ┆          ┆            │\n",
       "└─────────────┴────────┴────────┴────────────┴───┴────────────┴────────────┴──────────┴────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 42)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>file_name</th><th>NOSE_x</th><th>NOSE_y</th><th>NOSE_score</th><th>LEFT_EYE_x</th><th>LEFT_EYE_y</th><th>LEFT_EYE_score</th><th>RIGHT_EYE_x</th><th>RIGHT_EYE_y</th><th>RIGHT_EYE_score</th><th>LEFT_EAR_x</th><th>LEFT_EAR_y</th><th>LEFT_EAR_score</th><th>RIGHT_EAR_x</th><th>RIGHT_EAR_y</th><th>RIGHT_EAR_score</th><th>LEFT_SHOULDER_x</th><th>LEFT_SHOULDER_y</th><th>LEFT_SHOULDER_score</th><th>RIGHT_SHOULDER_x</th><th>RIGHT_SHOULDER_y</th><th>RIGHT_SHOULDER_score</th><th>LEFT_ELBOW_x</th><th>LEFT_ELBOW_y</th><th>LEFT_ELBOW_score</th><th>RIGHT_ELBOW_x</th><th>RIGHT_ELBOW_y</th><th>RIGHT_ELBOW_score</th><th>LEFT_WRIST_x</th><th>LEFT_WRIST_y</th><th>LEFT_WRIST_score</th><th>RIGHT_WRIST_x</th><th>RIGHT_WRIST_y</th><th>RIGHT_WRIST_score</th><th>LEFT_HIP_x</th><th>LEFT_HIP_y</th><th>LEFT_HIP_score</th><th>RIGHT_HIP_x</th><th>RIGHT_HIP_y</th><th>RIGHT_HIP_score</th><th>class_no</th><th>class_name</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;ergonomis\\DSC02412.JPG&quot;</td><td>2673.0</td><td>1426.0</td><td>0.6860288</td><td>2742.0</td><td>1352.0</td><td>0.5782869</td><td>2587.0</td><td>1360.0</td><td>0.6361119</td><td>2851.0</td><td>1428.0</td><td>0.763622</td><td>2451.0</td><td>1449.0</td><td>0.709723</td><td>3015.0</td><td>1902.0</td><td>0.711977</td><td>2257.0</td><td>1916.0</td><td>0.7672756</td><td>3173.0</td><td>2415.0</td><td>0.658837</td><td>2157.0</td><td>2475.0</td><td>0.703141</td><td>3157.0</td><td>2557.0</td><td>0.440902</td><td>2205.0</td><td>2631.0</td><td>0.334904</td><td>2893.0</td><td>2918.0</td><td>0.447213</td><td>2432.0</td><td>2901.0</td><td>0.5723911</td><td>0</td><td>&quot;ergonomis&quot;</td></tr><tr><td>&quot;ergonomis\\DSC02414.JPG&quot;</td><td>2553.0</td><td>1548.0</td><td>0.6246008</td><td>2645.0</td><td>1465.0</td><td>0.405759</td><td>2488.0</td><td>1457.0</td><td>0.49856</td><td>2805.0</td><td>1512.0</td><td>0.657731</td><td>2427.0</td><td>1489.0</td><td>0.566506</td><td>2995.0</td><td>1900.0</td><td>0.6918683</td><td>2262.0</td><td>1900.0</td><td>0.6520261</td><td>3030.0</td><td>2511.0</td><td>0.793446</td><td>1991.0</td><td>2432.0</td><td>0.5237641</td><td>2623.0</td><td>2633.0</td><td>0.7455008</td><td>1606.0</td><td>2570.0</td><td>0.641524</td><td>2749.0</td><td>3070.0</td><td>0.390012</td><td>2271.0</td><td>3009.0</td><td>0.5088232</td><td>0</td><td>&quot;ergonomis&quot;</td></tr><tr><td>&quot;ergonomis\\DSC02416.JPG&quot;</td><td>2811.0</td><td>1522.0</td><td>0.4514594</td><td>2869.0</td><td>1428.0</td><td>0.7665354</td><td>2712.0</td><td>1434.0</td><td>0.6812546</td><td>2896.0</td><td>1464.0</td><td>0.366023</td><td>2503.0</td><td>1490.0</td><td>0.674537</td><td>3044.0</td><td>1925.0</td><td>0.79644</td><td>2277.0</td><td>1934.0</td><td>0.826779</td><td>3267.0</td><td>2465.0</td><td>0.514814</td><td>2165.0</td><td>2508.0</td><td>0.670309</td><td>3631.0</td><td>2616.0</td><td>0.7749762</td><td>2415.0</td><td>2661.0</td><td>0.381569</td><td>2920.0</td><td>3101.0</td><td>0.5792116</td><td>2453.0</td><td>3108.0</td><td>0.5448222</td><td>0</td><td>&quot;ergonomis&quot;</td></tr><tr><td>&quot;ergonomis\\DSC02418.JPG&quot;</td><td>2654.0</td><td>1438.0</td><td>0.5282986</td><td>2731.0</td><td>1362.0</td><td>0.493264</td><td>2566.0</td><td>1370.0</td><td>0.449793</td><td>2842.0</td><td>1430.0</td><td>0.749468</td><td>2449.0</td><td>1465.0</td><td>0.608965</td><td>3016.0</td><td>1913.0</td><td>0.7614244</td><td>2282.0</td><td>1911.0</td><td>0.7253464</td><td>3171.0</td><td>2504.0</td><td>0.6839093</td><td>2126.0</td><td>2538.0</td><td>0.5690689</td><td>3031.0</td><td>2791.0</td><td>0.298675</td><td>2337.0</td><td>2777.0</td><td>0.193512</td><td>2888.0</td><td>2989.0</td><td>0.543253</td><td>2411.0</td><td>2988.0</td><td>0.5330165</td><td>0</td><td>&quot;ergonomis&quot;</td></tr><tr><td>&quot;ergonomis\\DSC02416.JPG&quot;</td><td>2557.0</td><td>1550.0</td><td>0.6233348</td><td>2648.0</td><td>1460.0</td><td>0.4383338</td><td>2494.0</td><td>1458.0</td><td>0.6176586</td><td>2841.0</td><td>1497.0</td><td>0.674965</td><td>2466.0</td><td>1486.0</td><td>0.5448318</td><td>3010.0</td><td>1893.0</td><td>0.776701</td><td>2278.0</td><td>1862.0</td><td>0.7632377</td><td>3072.0</td><td>2539.0</td><td>0.7402708</td><td>1983.0</td><td>2402.0</td><td>0.5696551</td><td>2737.0</td><td>2744.0</td><td>0.286435</td><td>1663.0</td><td>2656.0</td><td>0.610937</td><td>2741.0</td><td>2973.0</td><td>0.5816682</td><td>2270.0</td><td>2919.0</td><td>0.606949</td><td>0</td><td>&quot;ergonomis&quot;</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b1c5aa07090ed6c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:45.545489Z",
     "start_time": "2024-07-27T02:42:45.526479Z"
    }
   },
   "source": [
    "df_to_process = df.clone()\n",
    "classes = df_to_process.select('class_name').unique().to_numpy()\n",
    "y = tf.keras.utils.to_categorical(df_to_process.select('class_no').to_numpy())\n",
    "X = df_to_process.drop(['file_name', 'class_name', 'class_no'])"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:50.229933Z",
     "start_time": "2024-07-27T02:42:50.201458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ],
   "id": "40f263420ff3523c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:50.260419Z",
     "start_time": "2024-07-27T02:42:50.233935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_center_point(landmarks, left_bodypart, right_bodypart):\n",
    "    \"\"\"Calculates the center point of the two given landmarks.\"\"\"\n",
    "\n",
    "    left = tf.gather(landmarks, left_bodypart.value, axis=1)\n",
    "    right = tf.gather(landmarks, right_bodypart.value, axis=1)\n",
    "    center = left * 0.5 + right * 0.5\n",
    "    return center\n",
    "\n",
    "\n",
    "def get_pose_size(landmarks, torso_size_multiplier=2.5):\n",
    "    \"\"\"Calculates pose size.\n",
    "  \n",
    "    It is the maximum of two values:\n",
    "      * Torso size multiplied by `torso_size_multiplier`\n",
    "      * Maximum distance from pose center to any pose landmark\n",
    "    \"\"\"\n",
    "    # Hips center\n",
    "    hips_center = get_center_point(landmarks, BodyPart.LEFT_HIP,\n",
    "                                   BodyPart.RIGHT_HIP)\n",
    "\n",
    "    # Shoulders center\n",
    "    shoulders_center = get_center_point(landmarks, BodyPart.LEFT_SHOULDER,\n",
    "                                        BodyPart.RIGHT_SHOULDER)\n",
    "\n",
    "    # Torso size as the minimum body size\n",
    "    torso_size = tf.linalg.norm(shoulders_center - hips_center)\n",
    "\n",
    "    # Pose center\n",
    "    pose_center_new = get_center_point(landmarks, BodyPart.LEFT_HIP,\n",
    "                                       BodyPart.RIGHT_HIP)\n",
    "    pose_center_new = tf.expand_dims(pose_center_new, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to\n",
    "    # perform substraction\n",
    "    pose_center_new = tf.broadcast_to(pose_center_new,\n",
    "                                      [tf.size(landmarks) // (13*2), 13, 2])\n",
    "\n",
    "    # Dist to pose center\n",
    "    d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n",
    "                  name=\"dist_to_pose_center\")\n",
    "    # Max dist to pose center\n",
    "    max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n",
    "\n",
    "    # Normalize scale\n",
    "    pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)\n",
    "\n",
    "    return pose_size\n",
    "\n",
    "\n",
    "def normalize_pose_landmarks(landmarks):\n",
    "    \"\"\"Normalizes the landmarks translation by moving the pose center to (0,0) and\n",
    "    scaling it to a constant pose size.\n",
    "    \"\"\"\n",
    "    # Move landmarks so that the pose center becomes (0,0)\n",
    "    pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP,\n",
    "                                   BodyPart.RIGHT_HIP)\n",
    "    pose_center = tf.expand_dims(pose_center, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to perform\n",
    "    # substraction\n",
    "    pose_center = tf.broadcast_to(pose_center,\n",
    "                                  [tf.size(landmarks) // (13*2), 13, 2])\n",
    "    landmarks = landmarks - pose_center\n",
    "\n",
    "    # Scale the landmarks to a constant pose size\n",
    "    pose_size = get_pose_size(landmarks)\n",
    "    landmarks /= pose_size\n",
    "\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "def landmarks_to_embedding(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    reshaped_inputs = layers.Reshape((13, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Normalize landmarks 2D\n",
    "    landmarks = normalize_pose_landmarks(reshaped_inputs[:, :, :2])\n",
    "\n",
    "    # Flatten the normalized landmark coordinates into a vector\n",
    "    return layers.Flatten()(landmarks)\n"
   ],
   "id": "f4e42c6be022f206",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:51.016109Z",
     "start_time": "2024-07-27T02:42:50.262419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = tf.keras.Input(shape=39)\n",
    "embedding = landmarks_to_embedding(inputs)\n",
    "\n",
    "layer = layers.Dense(128, activation='relu')(embedding)\n",
    "layer = layers.Dropout(0.5)(layer)\n",
    "layer = layers.Dense(64, activation='relu')(layer)\n",
    "layer = layers.Dropout(0.5)(layer)\n",
    "outputs = layers.Dense(2, activation='softmax')(layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ],
   "id": "77b21653615802d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 39)]         0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 13, 3)        0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 13, 2)       0           ['reshape[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather (TFOpLambd  (None, 2)           0           ['tf.__operators__.getitem[0][0]'\n",
      " a)                                                              ]                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_1 (TFOpLam  (None, 2)           0           ['tf.__operators__.getitem[0][0]'\n",
      " bda)                                                            ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 2)            0           ['tf.compat.v1.gather[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_1[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 2)           0           ['tf.math.multiply[0][0]',       \n",
      " da)                                                              'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.size (TFOpLambda)  ()                  0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 2)         0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div (TFOpLa  ()                  0           ['tf.compat.v1.size[0][0]']      \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.broadcast_to (TFOpLambda)   (None, 13, 2)        0           ['tf.expand_dims[0][0]',         \n",
      "                                                                  'tf.compat.v1.floor_div[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 13, 2)        0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'tf.broadcast_to[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_6 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_7 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_6[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_7[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 2)           0           ['tf.math.multiply_6[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_7[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.size_1 (TFOpLambd  ()                  0           ['tf.math.subtract[0][0]']       \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_4 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_5 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_2 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_3 (TFOpLam  (None, 2)           0           ['tf.math.subtract[0][0]']       \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 1, 2)         0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.floor_div_1 (TFOp  ()                  0           ['tf.compat.v1.size_1[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_4[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_5[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 2)           0           ['tf.compat.v1.gather_3[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.broadcast_to_1 (TFOpLambda)  (None, 13, 2)       0           ['tf.expand_dims_1[0][0]',       \n",
      "                                                                  'tf.compat.v1.floor_div_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 2)           0           ['tf.math.multiply_4[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 2)           0           ['tf.math.multiply_2[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_3[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 13, 2)       0           ['tf.math.subtract[0][0]',       \n",
      " )                                                                'tf.broadcast_to_1[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 2)           0           ['tf.__operators__.add_2[0][0]', \n",
      " )                                                                'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.gather_8 (TFOpLam  (13, 2)             0           ['tf.math.subtract_2[0][0]']     \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.norm (TFOpLambda)  ()                  0           ['tf.math.subtract_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.norm_1 (TFOpLambd  (2,)                0           ['tf.compat.v1.gather_8[0][0]']  \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  ()                  0           ['tf.compat.v1.norm[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  ()                  0           ['tf.compat.v1.norm_1[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum (TFOpLambda)   ()                   0           ['tf.math.multiply_8[0][0]',     \n",
      "                                                                  'tf.math.reduce_max[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 13, 2)        0           ['tf.math.subtract[0][0]',       \n",
      "                                                                  'tf.math.maximum[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 26)           0           ['tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          3456        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            130         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,842\n",
      "Trainable params: 11,842\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:51.031419Z",
     "start_time": "2024-07-27T02:42:51.018250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def log_confusion_matrix(cm, title=None, cmap='Blues', class_names=classes):\n",
    "    \"\"\"Plots the confusion matrix.\"\"\"\n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "    plt.rcParams[\"font.size\"] = 10\n",
    "    fig, ax = plt.subplots(figsize=(7, 6), dpi=300)\n",
    "    sns.heatmap(cm, annot=True, cmap=cmap,\n",
    "                ax=ax, annot_kws={\"fontsize\": 11},\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    ax.set_xlabel('Predicted Class')\n",
    "    ax.set_ylabel('Actual Class')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    # log the confusion matrix\n",
    "    live.log_image('confusion_matrix.png', fig)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "def log_roc_auc_curve(y_true, y_pred_proba):\n",
    "    fig, ax = plt.subplots(figsize=(7, 6), dpi=300)\n",
    "    skplt.metrics.plot_roc(y_true, y_pred_proba, ax=ax)\n",
    "    live.log_image('roc_auc_curve.png', fig)\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ],
   "id": "d7dd53b2f53ab52c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T02:42:51.122388Z",
     "start_time": "2024-07-27T02:42:51.109252Z"
    }
   },
   "cell_type": "code",
   "source": "tf.keras.backend.clear_session()",
   "id": "8787bdb74f68850d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T02:43:35.278824Z",
     "start_time": "2024-07-27T02:42:51.415639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Add a checkpoint callback to store the checkpoint that has the highest\n",
    "# validation accuracy.\n",
    "checkpoint_path = \"dumps/weights.best.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                             monitor='val_accuracy',\n",
    "                                             verbose=1,\n",
    "                                             save_best_only=True,\n",
    "                                             mode='max')\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                              patience=20)\n",
    "\n",
    "# Start training\n",
    "with Live(report='html') as live:\n",
    "    history = model.fit(X_train.to_numpy(), y_train,\n",
    "                        epochs=200,\n",
    "                        batch_size=16,\n",
    "                        validation_data=(X_val.to_numpy(), y_val),\n",
    "                        callbacks=[checkpoint, earlystopping, DVCLiveCallback(live=live)])\n",
    "    model.save('dumps/mymodel.keras')\n",
    "    live.log_artifact('dumps/mymodel.keras', type='model')\n",
    "    test_loss, test_accuracy = model.evaluate(X_test.to_numpy(), y_test)\n",
    "\n",
    "    # Classify pose in the TEST dataset using the trained model\n",
    "    y_pred_proba = model.predict(X_test.to_numpy())\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    y_test_ravel = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # log test metric\n",
    "    live.log_metric('test_loss', test_loss)\n",
    "    live.log_metric('test_accuracy', test_accuracy)\n",
    "    live.log_metric('test_recall', recall_score(y_test_ravel, y_pred))\n",
    "    live.log_metric('test_precision', precision_score(y_test_ravel, y_pred))\n",
    "    live.log_metric('test_f1', f1_score(y_test_ravel, y_pred))\n",
    "    live.log_metric('test_roc_auc', roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "    # Convert the prediction result to class name\n",
    "    y_pred_label = [classes[i][0] for i in y_pred]\n",
    "    y_true_label = [classes[i][0] for i in y_test_ravel]\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    cm = confusion_matrix(y_test_ravel, y_pred)\n",
    "    log_confusion_matrix(cm, class_names=['ergonomic', 'non-ergonomic'])\n",
    "    log_roc_auc_curve(y_test_ravel, y_pred_proba)\n",
    "\n",
    "# Print the classification report\n",
    "print('\\nClassification Report:\\n', classification_report(y_true_label,\n",
    "                                                          y_pred_label))"
   ],
   "id": "c99732cf831dc7c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.6554 - accuracy: 0.6039\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69032, saving model to dumps\\weights.best.hdf5\n",
      "78/78 [==============================] - 3s 27ms/step - loss: 0.6543 - accuracy: 0.6048 - val_loss: 0.5962 - val_accuracy: 0.6903\n",
      "Epoch 2/200\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.5418 - accuracy: 0.7800\n",
      "Epoch 2: val_accuracy improved from 0.69032 to 0.87097, saving model to dumps\\weights.best.hdf5\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.5405 - accuracy: 0.7806 - val_loss: 0.3966 - val_accuracy: 0.8710\n",
      "Epoch 3/200\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.4039 - accuracy: 0.8531\n",
      "Epoch 3: val_accuracy improved from 0.87097 to 0.87742, saving model to dumps\\weights.best.hdf5\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.4059 - accuracy: 0.8516 - val_loss: 0.3011 - val_accuracy: 0.8774\n",
      "Epoch 4/200\n",
      "76/78 [============================>.] - ETA: 0s - loss: 0.3727 - accuracy: 0.8413\n",
      "Epoch 4: val_accuracy improved from 0.87742 to 0.88387, saving model to dumps\\weights.best.hdf5\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.3710 - accuracy: 0.8427 - val_loss: 0.2843 - val_accuracy: 0.8839\n",
      "Epoch 5/200\n",
      "74/78 [===========================>..] - ETA: 0s - loss: 0.3385 - accuracy: 0.8623\n",
      "Epoch 5: val_accuracy improved from 0.88387 to 0.90323, saving model to dumps\\weights.best.hdf5\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.3460 - accuracy: 0.8597 - val_loss: 0.2714 - val_accuracy: 0.9032\n",
      "Epoch 6/200\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.3488 - accuracy: 0.8669\n",
      "Epoch 6: val_accuracy did not improve from 0.90323\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.3488 - accuracy: 0.8669 - val_loss: 0.2897 - val_accuracy: 0.8774\n",
      "Epoch 7/200\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.3348 - accuracy: 0.8653\n",
      "Epoch 7: val_accuracy improved from 0.90323 to 0.90968, saving model to dumps\\weights.best.hdf5\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.3335 - accuracy: 0.8661 - val_loss: 0.2596 - val_accuracy: 0.9097\n",
      "Epoch 8/200\n",
      "71/78 [==========================>...] - ETA: 0s - loss: 0.3216 - accuracy: 0.8680\n",
      "Epoch 8: val_accuracy did not improve from 0.90968\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.3248 - accuracy: 0.8685 - val_loss: 0.2633 - val_accuracy: 0.9097\n",
      "Epoch 9/200\n",
      "67/78 [========================>.....] - ETA: 0s - loss: 0.3209 - accuracy: 0.8759\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    ergonomis       0.93      0.76      0.84        92\n",
      "non-ergonomis       0.72      0.92      0.81        63\n",
      "\n",
      "     accuracy                           0.83       155\n",
      "    macro avg       0.83      0.84      0.82       155\n",
      " weighted avg       0.85      0.83      0.83       155\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
