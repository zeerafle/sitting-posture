{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "QYPYOpo4V3EA",
    "ExecuteTime": {
     "end_time": "2024-07-25T03:25:33.404846Z",
     "start_time": "2024-07-25T03:25:28.459446Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "DATA_DIR = 'data'",
   "metadata": {
    "id": "aRkKXZIFW5Qv",
    "ExecuteTime": {
     "end_time": "2024-07-25T03:25:40.093436Z",
     "start_time": "2024-07-25T03:25:40.079436Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "The MoveNet output is a tensor of shape 1 x 1 x 17 x 3 because:\n",
    "\n",
    "- The first dimension (1) represents the batch size, as you are only processing one image at a time.\n",
    "- The second dimension (1) is not used and can be ignored.\n",
    "- The third dimension (17) represents the 17 keypoints detected by MoveNet for a single pose.\n",
    "- The fourth dimension (3) represents the y-coordinate, x-coordinate and confidence score of each keypoint."
   ],
   "metadata": {
    "id": "lsi60GtTaS59"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T03:56:01.061463Z",
     "start_time": "2024-07-25T03:56:01.049466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class KeypointsExtract(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(KeypointsExtract, self).__init__()\n",
    "        self.model = hub.load(\"https://www.kaggle.com/models/google/movenet/TensorFlow2/singlepose-thunder/4\")\n",
    "        self.movenet = self.model.signatures['serving_default']\n",
    "        \n",
    "    def call(self, images):\n",
    "        def process_single_image(image):\n",
    "            image = tf.expand_dims(image, axis=0)\n",
    "            image = tf.cast(image, dtype=tf.int32)\n",
    "            keypoints = self.movenet(image)['output_0']\n",
    "            keypoints = tf.squeeze(keypoints)\n",
    "            # return only the first 13 keypoints and their coordinates\n",
    "            return tf.reshape(keypoints[:13,:3], [13*3])\n",
    "        \n",
    "        keypoints_batch = tf.map_fn(process_single_image, images, fn_output_signature=tf.float32)\n",
    "        return keypoints_batch"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T03:56:01.551022Z",
     "start_time": "2024-07-25T03:56:01.379022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_ds, test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    image_size=(256, 256),\n",
    "    seed=42,\n",
    "    validation_split=0.1,\n",
    "    subset=\"both\",\n",
    "    crop_to_aspect_ratio=True\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1722 files belonging to 2 classes.\n",
      "Using 1550 files for training.\n",
      "Using 172 files for validation.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T03:56:38.377309Z",
     "start_time": "2024-07-25T03:56:26.110657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "keypoints_extract = KeypointsExtract()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(256, 256, 3)),\n",
    "    keypoints_extract,\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keypoints_extract_6 (Keypoi  (None, 39)               0         \n",
      " ntsExtract)                                                     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               5120      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,441\n",
      "Trainable params: 13,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-25T03:56:44.623834Z"
    }
   },
   "cell_type": "code",
   "source": "model.fit(train_ds, epochs=10)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "execution_count": null
  }
 ]
}
