{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeerafle/sitting-posture/blob/generated-data/sdxl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaAJk33ppFw1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "!apt -y update -qq\n",
        "!apt -y install -qq aria2\n",
        "# !pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "# !pip install -q xformers==0.0.16 triton==2.0.0 -U\n",
        "# !pip install -q mediapipe==0.9.1.0 addict yapf fvcore omegaconf\n",
        "\n",
        "!git clone https://github.com/comfyanonymous/ComfyUI.git\n",
        "%cd /content/ComfyUI\n",
        "!pip install -q -r requirements.txt\n",
        "!git reset --hard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "os.environ['CIVITAI_TOKEN'] = userdata.get('CIVITAI_TOKEN')"
      ],
      "metadata": {
        "id": "JQL_oY5HfTar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-Zwv5GLIF09-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# Set up environment\n",
        "COMFYUI_DIR=/content/ComfyUI\n",
        "\n",
        "NODES=(\n",
        "    \"https://github.com/ltdrdata/ComfyUI-Manager\"\n",
        "    \"https://github.com/cubiq/ComfyUI_essentials\"\n",
        "    \"https://github.com/rgthree/rgthree-comfy\"\n",
        "    \"https://github.com/Fannovel16/comfyui_controlnet_aux\"\n",
        "    \"https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes\"\n",
        "    \"https://github.com/adieyal/comfyui-dynamicprompts\"\n",
        ")\n",
        "\n",
        "# Model arrays\n",
        "CHECKPOINT_MODELS=(\n",
        "    \"https://civitai.com/api/download/models/1759168?type=Model&format=SafeTensor&size=full&fp=fp16\"\n",
        "    # \"https://civitai.com/api/download/models/1943922?type=Model&format=SafeTensor&size=pruned&fp=fp16\"\n",
        ")\n",
        "\n",
        "LORA_MODELS=(\n",
        ")\n",
        "\n",
        "CONTROLNET_MODELS=(\n",
        "    \"https://huggingface.co/xinsir/controlnet-union-sdxl-1.0/resolve/main/diffusion_pytorch_model_promax.safetensors?download=true\"\n",
        ")\n",
        "\n",
        "\n",
        "# Create directories if they don't exist\n",
        "mkdir -p \"${COMFYUI_DIR}/models/checkpoints\"\n",
        "mkdir -p \"${COMFYUI_DIR}/models/loras\"\n",
        "mkdir -p \"${COMFYUI_DIR}/models/controlnet\"\n",
        "\n",
        "# Print token values for debugging\n",
        "echo \"HF_TOKEN is set to: ${HF_TOKEN}\"\n",
        "echo \"CIVITAI_TOKEN is set to: ${CIVITAI_TOKEN}\"\n",
        "\n",
        "\n",
        "# Download function using aria2c\n",
        "function download_model() {\n",
        "    local url=\"$1\"\n",
        "    local destination=\"$2\"\n",
        "    local model_type=\"$3\"\n",
        "    local filename=\"\"\n",
        "\n",
        "    echo \"Downloading $model_type: $url\"\n",
        "    echo \"Destination: $destination\"\n",
        "\n",
        "    if [[ -n $HF_TOKEN && $url =~ ^https://([a-zA-Z0-9_-]+\\.)?huggingface\\.co(/|$|\\?) ]]; then\n",
        "        # HuggingFace download with authorization header\n",
        "        filename=$(basename \"$url\" | sed 's/\\?.*//')\n",
        "        aria2c --log-level=error \\\n",
        "               --header=\"Authorization: Bearer $HF_TOKEN\" \\\n",
        "               --continue=true \\\n",
        "               --max-connection-per-server=8 \\\n",
        "               --split=8 \\\n",
        "               --min-split-size=1M \\\n",
        "               --summary-interval=10 \\\n",
        "               --dir=\"$destination\" -o \"$filename\" \"$url\"\n",
        "    elif [[ -n $CIVITAI_TOKEN && $url =~ ^https://([a-zA-Z0-9_-]+\\.)?civitai\\.com(/|$|\\?) ]]; then\n",
        "        # Civitai download with token parameter and use content-disposition for filename\n",
        "        if [[ $url == *\"?\"* ]]; then\n",
        "            download_url=\"${url}&token=${CIVITAI_TOKEN}\"\n",
        "        else\n",
        "            download_url=\"${url}?token=${CIVITAI_TOKEN}\"\n",
        "        fi\n",
        "        aria2c --log-level=error \\\n",
        "               --content-disposition \\\n",
        "               --continue=true \\\n",
        "               --max-connection-per-server=8 \\\n",
        "               --split=8 \\\n",
        "               --min-split-size=1M \\\n",
        "               --summary-interval=10 \\\n",
        "               --dir=\"$destination\" \"$download_url\"\n",
        "    else\n",
        "        # Generic download\n",
        "        filename=$(basename \"$url\" | sed 's/\\?.*//')\n",
        "        aria2c --log-level=error \\\n",
        "               --continue=true \\\n",
        "               --max-connection-per-server=8 \\\n",
        "               --split=8 \\\n",
        "               --min-split-size=1M \\\n",
        "               --summary-interval=10 \\\n",
        "               --dir=\"$destination\" -o \"$filename\" \"$url\"\n",
        "    fi\n",
        "\n",
        "    if [ $? -eq 0 ]; then\n",
        "        echo \"✓ Successfully downloaded $model_type\"\n",
        "    else\n",
        "        echo \"✗ Failed to download $model_type: $url\"\n",
        "    fi\n",
        "    echo \"----------------------------------------\"\n",
        "}\n",
        "\n",
        "function provisioning_get_nodes() {\n",
        "    for repo in \"${NODES[@]}\"; do\n",
        "        dir=\"${repo##*/}\"\n",
        "        path=\"${COMFYUI_DIR}/custom_nodes/${dir}\"\n",
        "        requirements=\"${path}/requirements.txt\"\n",
        "        if [[ -d $path ]]; then\n",
        "            if [[ ${AUTO_UPDATE,,} != \"false\" ]]; then\n",
        "                printf \"Updating node: %s...\\n\" \"${repo}\"\n",
        "                ( cd \"$path\" && git pull )\n",
        "                if [[ -e $requirements ]]; then\n",
        "                   pip install --no-cache-dir -r \"$requirements\"\n",
        "                fi\n",
        "            fi\n",
        "        else\n",
        "            printf \"Downloading node: %s...\\n\" \"${repo}\"\n",
        "            git clone \"${repo}\" \"${path}\" --recursive\n",
        "            if [[ -e $requirements ]]; then\n",
        "                pip install --no-cache-dir -r \"${requirements}\"\n",
        "            fi\n",
        "        fi\n",
        "    done\n",
        "}\n",
        "\n",
        "# Download and install nodes\n",
        "echo \"Starting node downloads...\"\n",
        "echo \"==========================\"\n",
        "provisioning_get_nodes\n",
        "\n",
        "# Download checkpoint models\n",
        "echo \"Starting checkpoint model downloads...\"\n",
        "echo \"========================================\"\n",
        "for url in \"${CHECKPOINT_MODELS[@]}\"; do\n",
        "    download_model \"$url\" \"${COMFYUI_DIR}/models/checkpoints\" \"Checkpoint Model\"\n",
        "done\n",
        "\n",
        "# Download LoRA models\n",
        "echo \"\"\n",
        "echo \"Starting LoRA model downloads...\"\n",
        "echo \"=================================\"\n",
        "for url in \"${LORA_MODELS[@]}\"; do\n",
        "    download_model \"$url\" \"${COMFYUI_DIR}/models/loras\" \"LoRA Model\"\n",
        "done\n",
        "\n",
        "# Download ControlNet models\n",
        "echo \"\"\n",
        "echo \"Starting ControlNet model downloads...\"\n",
        "echo \"=================================\"\n",
        "for url in \"${CONTROLNET_MODELS[@]}\"; do\n",
        "    download_model \"$url\" \"${COMFYUI_DIR}/models/controlnet\" \"ControlNet Model\"\n",
        "done\n",
        "\n",
        "echo \"\"\n",
        "echo \"All downloads completed!\"\n",
        "echo \"========================\"\n",
        "echo \"Checkpoint models saved to: ${COMFYUI_DIR}/models/checkpoints\"\n",
        "echo \"LoRA models saved to: ${COMFYUI_DIR}/models/loras\"\n",
        "echo \"ControlNet models saved to: ${COMFYUI_DIR}/models/controlnet\"\n",
        "\n",
        "\n",
        "# Optional: List downloaded files\n",
        "echo \"\"\n",
        "echo \"Downloaded checkpoint models:\"\n",
        "ls -la \"${COMFYUI_DIR}/models/checkpoints/\"\n",
        "echo \"\"\n",
        "echo \"Downloaded LoRA models:\"\n",
        "ls -la \"${COMFYUI_DIR}/models/loras/\"\n",
        "echo \"\"\n",
        "echo \"Downloaded ControlNet models:\"\n",
        "ls -la \"${COMFYUI_DIR}/models/controlnet/\""
      ],
      "metadata": {
        "id": "AUV36yTVe-be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /content/cloudflared-linux-amd64 && chmod 777 /content/cloudflared-linux-amd64"
      ],
      "metadata": {
        "id": "YeGFLemTSB0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import atexit, requests, subprocess, time, re, os\n",
        "from random import randint\n",
        "from threading import Timer\n",
        "from queue import Queue\n",
        "def cloudflared(port, metrics_port, output_queue):\n",
        "    atexit.register(lambda p: p.terminate(), subprocess.Popen(['/content/cloudflared-linux-amd64', 'tunnel', '--url', f'http://127.0.0.1:{port}', '--metrics', f'127.0.0.1:{metrics_port}'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT))\n",
        "    attempts, tunnel_url = 0, None\n",
        "    while attempts < 10 and not tunnel_url:\n",
        "        attempts += 1\n",
        "        time.sleep(3)\n",
        "        try:\n",
        "            tunnel_url = re.search(\"(?P<url>https?:\\/\\/[^\\s]+.trycloudflare.com)\", requests.get(f'http://127.0.0.1:{metrics_port}/metrics').text).group(\"url\")\n",
        "        except:\n",
        "            pass\n",
        "    if not tunnel_url:\n",
        "        raise Exception(\"Can't connect to Cloudflare Edge\")\n",
        "    output_queue.put(tunnel_url)\n",
        "output_queue, metrics_port = Queue(), randint(8100, 9000)\n",
        "thread = Timer(2, cloudflared, args=(8188, metrics_port, output_queue))\n",
        "thread.start()\n",
        "thread.join()\n",
        "tunnel_url = output_queue.get()\n",
        "os.environ['webui_url'] = tunnel_url\n",
        "print(tunnel_url)"
      ],
      "metadata": {
        "id": "LavNtd74TwFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python main.py --dont-print-server --output-directory \"/content/drive/MyDrive/ComfyUI/output\""
      ],
      "metadata": {
        "id": "5evLRlbLfyFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from urllib import request\n",
        "\n",
        "#This is the ComfyUI api prompt format.\n",
        "\n",
        "#If you want it for a specific workflow you can \"enable dev mode options\"\n",
        "#in the settings of the UI (gear beside the \"Queue Size: \") this will enable\n",
        "#a button on the UI to save workflows in api format.\n",
        "\n",
        "#keep in mind ComfyUI is pre alpha software so this format will change a bit.\n",
        "\n",
        "#this is the one for the default workflow\n",
        "prompt_text = \"\"\"\n",
        "{\n",
        "    \"3\": {\n",
        "        \"class_type\": \"KSampler\",\n",
        "        \"inputs\": {\n",
        "            \"cfg\": 8,\n",
        "            \"denoise\": 1,\n",
        "            \"latent_image\": [\n",
        "                \"5\",\n",
        "                0\n",
        "            ],\n",
        "            \"model\": [\n",
        "                \"4\",\n",
        "                0\n",
        "            ],\n",
        "            \"negative\": [\n",
        "                \"7\",\n",
        "                0\n",
        "            ],\n",
        "            \"positive\": [\n",
        "                \"6\",\n",
        "                0\n",
        "            ],\n",
        "            \"sampler_name\": \"euler\",\n",
        "            \"scheduler\": \"normal\",\n",
        "            \"seed\": 8566257,\n",
        "            \"steps\": 20\n",
        "        }\n",
        "    },\n",
        "    \"4\": {\n",
        "        \"class_type\": \"CheckpointLoaderSimple\",\n",
        "        \"inputs\": {\n",
        "            \"ckpt_name\": \"v1-5-pruned-emaonly.safetensors\"\n",
        "        }\n",
        "    },\n",
        "    \"5\": {\n",
        "        \"class_type\": \"EmptyLatentImage\",\n",
        "        \"inputs\": {\n",
        "            \"batch_size\": 1,\n",
        "            \"height\": 512,\n",
        "            \"width\": 512\n",
        "        }\n",
        "    },\n",
        "    \"6\": {\n",
        "        \"class_type\": \"CLIPTextEncode\",\n",
        "        \"inputs\": {\n",
        "            \"clip\": [\n",
        "                \"4\",\n",
        "                1\n",
        "            ],\n",
        "            \"text\": \"masterpiece best quality girl\"\n",
        "        }\n",
        "    },\n",
        "    \"7\": {\n",
        "        \"class_type\": \"CLIPTextEncode\",\n",
        "        \"inputs\": {\n",
        "            \"clip\": [\n",
        "                \"4\",\n",
        "                1\n",
        "            ],\n",
        "            \"text\": \"bad hands\"\n",
        "        }\n",
        "    },\n",
        "    \"8\": {\n",
        "        \"class_type\": \"VAEDecode\",\n",
        "        \"inputs\": {\n",
        "            \"samples\": [\n",
        "                \"3\",\n",
        "                0\n",
        "            ],\n",
        "            \"vae\": [\n",
        "                \"4\",\n",
        "                2\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    \"9\": {\n",
        "        \"class_type\": \"SaveImage\",\n",
        "        \"inputs\": {\n",
        "            \"filename_prefix\": \"ComfyUI\",\n",
        "            \"images\": [\n",
        "                \"8\",\n",
        "                0\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "sdxl_controlnet_worfkflow =\n",
        "\n",
        "def queue_prompt(prompt):\n",
        "    p = {\"prompt\": prompt}\n",
        "\n",
        "    # If the workflow contains API nodes, you can add a Comfy API key to the `extra_data`` field of the payload.\n",
        "    # p[\"extra_data\"] = {\n",
        "    #     \"api_key_comfy_org\": \"comfyui-87d01e28d*******************************************************\"  # replace with real key\n",
        "    # }\n",
        "    # See: https://docs.comfy.org/tutorials/api-nodes/overview\n",
        "    # Generate a key here: https://platform.comfy.org/login\n",
        "\n",
        "    data = json.dumps(p).encode('utf-8')\n",
        "    req =  request.Request(\"http://127.0.0.1:8188/prompt\", data=data)\n",
        "    request.urlopen(req)\n",
        "\n",
        "\n",
        "prompt = json.loads(prompt_text)\n",
        "#set the text prompt for our positive CLIPTextEncode\n",
        "prompt[\"6\"][\"inputs\"][\"text\"] = \"masterpiece best quality man\"\n",
        "\n",
        "#set the seed for our KSampler node\n",
        "prompt[\"3\"][\"inputs\"][\"seed\"] = 5\n",
        "\n",
        "\n",
        "queue_prompt(prompt)\n",
        "\n"
      ],
      "metadata": {
        "id": "rqp_s7cnsHrK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}